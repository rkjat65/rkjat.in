{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa681f2c-7678-408f-bc55-63cca23e2970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MyNeta Lok Sabha 2024 - FIXED Scraper\n",
      "============================================================\n",
      "\n",
      "Testing with page 1...\n",
      "  ‚úó Page 1: Error - cannot access local variable 'headers' where it is not associated with a value\n",
      "\n",
      "‚úó FAILED! The scraper needs more debugging.\n",
      "\n",
      "Let me try a different approach...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MyNeta Lok Sabha 2024 - FIXED Scraper\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuration\n",
    "BASE_URL = \"https://myneta.info/LokSabha2024/index.php\"\n",
    "DELAY_SECONDS = 3\n",
    "OUTPUT_FILE = '../data/raw/lok_sabha_2024_full.xlsx'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "}\n",
    "\n",
    "def scrape_page(page_num):\n",
    "    \"\"\"Scrape a single page - FIXED VERSION\"\"\"\n",
    "    try:\n",
    "        # Build URL\n",
    "        params = {\n",
    "            'action': 'summary',\n",
    "            'subAction': 'candidates_analyzed',\n",
    "            'sort': 'candidate',\n",
    "            'page': page_num\n",
    "        }\n",
    "        \n",
    "        # Make request\n",
    "        response = requests.get(BASE_URL, params=params, headers=headers, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse with BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find the main data table (it has class 'mytable' or similar)\n",
    "        # Let's find all tables and get the one with candidate data\n",
    "        tables = soup.find_all('table')\n",
    "        \n",
    "        # The candidate table has headers: Sno, Candidate, Constituency, Party, etc.\n",
    "        candidate_table = None\n",
    "        for table in tables:\n",
    "            # Check if this table has the right headers\n",
    "            headers_row = table.find('tr')\n",
    "            if headers_row:\n",
    "                header_text = headers_row.get_text()\n",
    "                if 'Candidate' in header_text and 'Constituency' in header_text and 'Party' in header_text:\n",
    "                    candidate_table = table\n",
    "                    break\n",
    "        \n",
    "        if candidate_table is None:\n",
    "            print(f\"  ‚úó Page {page_num}: Could not find candidate table\")\n",
    "            return None\n",
    "        \n",
    "        # Parse the table\n",
    "        rows = []\n",
    "        header_row = candidate_table.find('tr')\n",
    "        headers = [th.get_text(strip=True) for th in header_row.find_all(['th', 'td'])]\n",
    "        \n",
    "        # Get all data rows (skip header)\n",
    "        for row in candidate_table.find_all('tr')[1:]:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 0:\n",
    "                row_data = []\n",
    "                for col in cols:\n",
    "                    # Get text, clean it up\n",
    "                    text = col.get_text(strip=True)\n",
    "                    # Remove extra whitespace\n",
    "                    text = ' '.join(text.split())\n",
    "                    row_data.append(text)\n",
    "                rows.append(row_data)\n",
    "        \n",
    "        if len(rows) > 0:\n",
    "            df = pd.DataFrame(rows, columns=headers[:len(rows[0])])\n",
    "            print(f\"  ‚úì Page {page_num}: {len(df)} records\")\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"  ‚úó Page {page_num}: No data rows found\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó Page {page_num}: Error - {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Test with just page 1 first\n",
    "print(\"\\nTesting with page 1...\")\n",
    "df_test = scrape_page(1)\n",
    "\n",
    "if df_test is not None and len(df_test) > 0:\n",
    "    print(\"\\n‚úì SUCCESS! Here's what we got:\")\n",
    "    print(f\"\\nShape: {df_test.shape}\")\n",
    "    print(f\"\\nColumns: {df_test.columns.tolist()}\")\n",
    "    print(f\"\\nFirst 3 rows:\")\n",
    "    display(df_test.head(3))\n",
    "    \n",
    "    # Ask if user wants to continue\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    proceed = input(\"Data looks good? Continue with all 84 pages? (y/n): \")\n",
    "    \n",
    "    if proceed.lower() == 'y':\n",
    "        print(\"\\nStarting full scrape...\")\n",
    "        all_data = [df_test]  # Start with page 1\n",
    "        \n",
    "        for page in range(2, 85):  # Pages 2-84\n",
    "            print(f\"\\n[{page}/84] Scraping page {page}...\")\n",
    "            df = scrape_page(page)\n",
    "            \n",
    "            if df is not None and len(df) > 0:\n",
    "                all_data.append(df)\n",
    "            \n",
    "            # Save progress every 10 pages\n",
    "            if page % 10 == 0:\n",
    "                temp_df = pd.concat(all_data, ignore_index=True)\n",
    "                temp_df.to_excel('../data/raw/lok_sabha_temp.xlsx', index=False)\n",
    "                print(f\"  üíæ Progress: {len(temp_df)} records saved\")\n",
    "            \n",
    "            # Delay\n",
    "            if page < 84:\n",
    "                time.sleep(DELAY_SECONDS)\n",
    "        \n",
    "        # Combine all\n",
    "        final_df = pd.concat(all_data, ignore_index=True)\n",
    "        final_df = final_df.drop_duplicates()\n",
    "        final_df.to_excel(OUTPUT_FILE, index=False)\n",
    "        \n",
    "        print(f\"\\n‚úì COMPLETE! {len(final_df)} records saved to {OUTPUT_FILE}\")\n",
    "    else:\n",
    "        print(\"\\nScraping cancelled. Fix any issues and try again.\")\n",
    "else:\n",
    "    print(\"\\n‚úó FAILED! The scraper needs more debugging.\")\n",
    "    print(\"\\nLet me try a different approach...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31f46107-2bf4-4952-864f-ba9c76de8165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 tables on the page\n",
      "\n",
      "============================================================\n",
      "TABLE 1:\n",
      "============================================================\n",
      "Headers: ['', '']\n",
      "Total rows: 1\n",
      "\n",
      "============================================================\n",
      "TABLE 2:\n",
      "============================================================\n",
      "Headers: ['', '']\n",
      "Total rows: 1\n",
      "\n",
      "============================================================\n",
      "TABLE 3:\n",
      "============================================================\n",
      "Headers: ['HIGHLIGHTS OF CANDIDATES']\n",
      "Total rows: 9\n",
      "First row sample: []\n",
      "\n",
      "============================================================\n",
      "TABLE 4:\n",
      "============================================================\n",
      "Headers: ['HIGHLIGHTS OF WINNERS']\n",
      "Total rows: 8\n",
      "First row sample: ['Total winners analyzed by NEW', '543']\n",
      "\n",
      "============================================================\n",
      "TABLE 5:\n",
      "============================================================\n",
      "Headers: ['Sno', 'Candidate‚àá', 'Constituency', 'Party', 'Criminal Case', 'Education', 'Total Assets', 'Liabilities']\n",
      "Total rows: 1\n",
      "\n",
      "============================================================\n",
      "TABLE 6:\n",
      "============================================================\n",
      "Headers: ['DONATE NOW√óShare On:', 'DONATE NOW√ó', 'Share On:', '', '', '', 'Download AppFollow us on', 'Download App', '', 'Follow us on']\n",
      "Total rows: 3\n",
      "First row sample: ['DONATE NOW√ó', 'Share On:', '', '', '']\n",
      "\n",
      "============================================================\n",
      "TABLE 7:\n",
      "============================================================\n",
      "Headers: ['DONATE NOW√ó', 'Share On:', '', '', '']\n",
      "Total rows: 1\n",
      "\n",
      "============================================================\n",
      "TABLE 8:\n",
      "============================================================\n",
      "Headers: ['Download App', '', 'Follow us on', '', '', '', '', '', '']\n",
      "Total rows: 1\n",
      "\n",
      "\n",
      "============================================================\n",
      "PANDAS READ_HTML RESULTS:\n",
      "============================================================\n",
      "Found 8 dataframes\n",
      "\n",
      "DataFrame 1: Shape (1, 2)\n",
      "Columns: [0, 1]\n",
      "    0   1\n",
      "0 NaN NaN\n",
      "\n",
      "DataFrame 2: Shape (1, 2)\n",
      "Columns: [0, 1]\n",
      "    0   1\n",
      "0 NaN NaN\n",
      "\n",
      "DataFrame 3: Shape (7, 2)\n",
      "Columns: [('HIGHLIGHTS OF CANDIDATES', 'Total number of constituencies analyzed'), ('Unnamed: 1_level_0', '543')]\n",
      "                  HIGHLIGHTS OF CANDIDATES Unnamed: 1_level_0\n",
      "   Total number of constituencies analyzed                543\n",
      "0         Total candidates analyzed by NEW               8338\n",
      "1  Candidates with declared criminal cases          1645(20%)\n",
      "\n",
      "DataFrame 4: Shape (7, 2)\n",
      "Columns: ['HIGHLIGHTS OF WINNERS', 'Unnamed: 1']\n",
      "                  HIGHLIGHTS OF WINNERS Unnamed: 1\n",
      "0         Total winners analyzed by NEW        543\n",
      "1  Winners with declared criminal cases  251 (46%)\n",
      "\n",
      "DataFrame 5: Shape (0, 8)\n",
      "Columns: ['Sno', 'Candidate‚àá', 'Constituency', 'Party', 'Criminal Case', 'Education', 'Total Assets', 'Liabilities']\n",
      "\n",
      "DataFrame 6: Shape (1, 2)\n",
      "Columns: [0, 1]\n",
      "                                                   0  \\\n",
      "0  DONATE NOW √ó  donate_now.onclick = function() ...   \n",
      "\n",
      "                           1  \n",
      "0  Download App Follow us on  \n",
      "\n",
      "DataFrame 7: Shape (1, 5)\n",
      "Columns: [0, 1, 2, 3, 4]\n",
      "                                                   0          1   2   3   4\n",
      "0  DONATE NOW √ó  donate_now.onclick = function() ...  Share On: NaN NaN NaN\n",
      "\n",
      "DataFrame 8: Shape (1, 9)\n",
      "Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "              0   1             2   3   4   5   6   7   8\n",
      "0  Download App NaN  Follow us on NaN NaN NaN NaN NaN NaN\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://myneta.info/LokSabha2024/index.php?action=summary&subAction=candidates_analyzed&sort=candidate&page=1\"\n",
    "\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find all tables\n",
    "tables = soup.find_all('table')\n",
    "print(f\"Found {len(tables)} tables on the page\\n\")\n",
    "\n",
    "# Check each table\n",
    "for i, table in enumerate(tables):\n",
    "    print(f\"=\"*60)\n",
    "    print(f\"TABLE {i+1}:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get headers\n",
    "    try:\n",
    "        header_row = table.find('tr')\n",
    "        if header_row:\n",
    "            headers = [th.get_text(strip=True) for th in header_row.find_all(['th', 'td'])]\n",
    "            print(f\"Headers: {headers[:10]}\")  # First 10 headers\n",
    "            \n",
    "            # Count rows\n",
    "            rows = table.find_all('tr')\n",
    "            print(f\"Total rows: {len(rows)}\")\n",
    "            \n",
    "            # Show first data row\n",
    "            if len(rows) > 1:\n",
    "                first_data = [td.get_text(strip=True) for td in rows[1].find_all('td')]\n",
    "                print(f\"First row sample: {first_data[:5]}\")\n",
    "    except:\n",
    "        print(\"Could not parse this table\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Also try pd.read_html\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PANDAS READ_HTML RESULTS:\")\n",
    "print(\"=\"*60)\n",
    "dfs = pd.read_html(url)\n",
    "print(f\"Found {len(dfs)} dataframes\")\n",
    "for i, df in enumerate(dfs):\n",
    "    print(f\"\\nDataFrame {i+1}: Shape {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    if len(df) > 0:\n",
    "        print(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22b2be5f-5235-4d20-b038-e2a1303a9713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MyNeta Scraper - Table 5 Extractor\n",
      "============================================================\n",
      "\n",
      "Testing page 1...\n",
      "  ‚úì Page 1: 0 records\n",
      "\n",
      "‚ùå Failed to scrape page 1. Need to debug further.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\575553623.py:20: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(response.text)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MyNeta Scraper - Table 5 Extractor\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def scrape_page(page_num):\n",
    "    \"\"\"Scrape page and get table 5 data\"\"\"\n",
    "    try:\n",
    "        url = f\"https://myneta.info/LokSabha2024/index.php?action=summary&subAction=candidates_analyzed&sort=candidate&page={page_num}\"\n",
    "        \n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Use pandas read_html to get all tables\n",
    "        dfs = pd.read_html(response.text)\n",
    "        \n",
    "        # Table 5 is index 4 (0-indexed)\n",
    "        if len(dfs) >= 5:\n",
    "            df = dfs[4]  # 5th table (index 4)\n",
    "            \n",
    "            # Clean the data\n",
    "            # Remove any empty rows\n",
    "            df = df.dropna(how='all')\n",
    "            \n",
    "            print(f\"  ‚úì Page {page_num}: {len(df)} records\")\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"  ‚úó Page {page_num}: Less than 5 tables found\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó Page {page_num}: Error - {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# TEST with page 1\n",
    "print(\"\\nTesting page 1...\")\n",
    "df_test = scrape_page(1)\n",
    "\n",
    "if df_test is not None and len(df_test) > 0:\n",
    "    print(\"\\n‚úì SUCCESS!\\n\")\n",
    "    print(f\"Shape: {df_test.shape}\")\n",
    "    print(f\"Columns: {df_test.columns.tolist()}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    display(df_test.head())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Sample data check:\")\n",
    "    print(f\"- Candidates found: {len(df_test)}\")\n",
    "    print(f\"- Sample candidate: {df_test['Candidate'].iloc[0] if 'Candidate' in df_test.columns else 'N/A'}\")\n",
    "    print(f\"- Sample party: {df_test['Party'].iloc[0] if 'Party' in df_test.columns else 'N/A'}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    proceed = input(\"\\nLooks good? Scrape all 84 pages? (y/n): \")\n",
    "    \n",
    "    if proceed.lower() == 'y':\n",
    "        print(\"\\nüöÄ Starting full scrape (84 pages √ó 3 sec = ~4 mins)\")\n",
    "        print(f\"Start time: {datetime.now().strftime('%H:%M:%S')}\\n\")\n",
    "        \n",
    "        all_data = [df_test]  # Start with page 1\n",
    "        failed_pages = []\n",
    "        \n",
    "        for page in range(2, 85):\n",
    "            print(f\"[{page}/84] \", end=\"\")\n",
    "            \n",
    "            df = scrape_page(page)\n",
    "            \n",
    "            if df is not None and len(df) > 0:\n",
    "                all_data.append(df)\n",
    "            else:\n",
    "                failed_pages.append(page)\n",
    "            \n",
    "            # Save progress every 10 pages\n",
    "            if page % 10 == 0:\n",
    "                temp_df = pd.concat(all_data, ignore_index=True)\n",
    "                temp_df.to_excel('../data/raw/lok_sabha_temp.xlsx', index=False)\n",
    "                print(f\"\\n  üíæ Progress saved: {len(temp_df)} total records\")\n",
    "            \n",
    "            # Respectful delay\n",
    "            if page < 84:\n",
    "                time.sleep(3)\n",
    "        \n",
    "        # Final combine\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Combining all data...\")\n",
    "        final_df = pd.concat(all_data, ignore_index=True)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        initial = len(final_df)\n",
    "        final_df = final_df.drop_duplicates()\n",
    "        final = len(final_df)\n",
    "        \n",
    "        # Save\n",
    "        final_df.to_excel('../data/raw/lok_sabha_2024_full.xlsx', index=False)\n",
    "        \n",
    "        print(f\"\\n‚úÖ SCRAPING COMPLETE!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Total records: {final}\")\n",
    "        print(f\"Duplicates removed: {initial - final}\")\n",
    "        print(f\"Failed pages: {len(failed_pages)}\")\n",
    "        if failed_pages:\n",
    "            print(f\"  Pages: {failed_pages}\")\n",
    "        print(f\"Saved to: lok_sabha_2024_full.xlsx\")\n",
    "        print(f\"End time: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Show final stats\n",
    "        print(\"\\nüìä DATASET SUMMARY:\")\n",
    "        print(f\"Shape: {final_df.shape}\")\n",
    "        print(f\"Columns: {final_df.columns.tolist()}\")\n",
    "        \n",
    "        # Store in variable for next analysis\n",
    "        df = final_df\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nCancelled. Ready when you are!\")\n",
    "        df = df_test\n",
    "else:\n",
    "    print(\"\\n‚ùå Failed to scrape page 1. Need to debug further.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6652273c-1b04-4069-a21a-8851822841fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPLETE DIAGNOSTIC\n",
      "======================================================================\n",
      "\n",
      "üìä METHOD 1: pd.read_html()\n",
      "----------------------------------------------------------------------\n",
      "Total tables found: 8\n",
      "\n",
      "\n",
      "Table 1:\n",
      "  Shape: (1, 2)\n",
      "  Columns: [0, 1]\n",
      "  First row: [nan, nan]\n",
      "\n",
      "\n",
      "Table 2:\n",
      "  Shape: (1, 2)\n",
      "  Columns: [0, 1]\n",
      "  First row: [nan, nan]\n",
      "\n",
      "\n",
      "Table 3:\n",
      "  Shape: (7, 2)\n",
      "  Columns: [('HIGHLIGHTS OF CANDIDATES', 'Total number of constituencies analyzed'), ('Unnamed: 1_level_0', '543')]\n",
      "  First row: ['Total candidates analyzed by NEW', '8338']\n",
      "\n",
      "\n",
      "Table 4:\n",
      "  Shape: (7, 2)\n",
      "  Columns: ['HIGHLIGHTS OF WINNERS', 'Unnamed: 1']\n",
      "  First row: ['Total winners analyzed by NEW', '543']\n",
      "\n",
      "\n",
      "Table 5:\n",
      "  Shape: (0, 8)\n",
      "  Columns: ['Sno', 'Candidate‚àá', 'Constituency', 'Party', 'Criminal Case', 'Education', 'Total Assets', 'Liabilities']\n",
      "\n",
      "\n",
      "Table 6:\n",
      "  Shape: (1, 2)\n",
      "  Columns: [0, 1]\n",
      "  First row: [\"DONATE NOW √ó  donate_now.onclick = function()  { var modal_2 = document.getElementById('myModal');  var span_2 = document.getElementsByClassName('close_2')[0];  modal_2.style.display = 'block'; // show modal  // When the user clicks on <span> (x), close the modal  span_2.onclick = function()  {  modal_2.style.display = 'none'; } } Share On:\", 'Download App Follow us on']\n",
      "\n",
      "\n",
      "Table 7:\n",
      "  Shape: (1, 5)\n",
      "  Columns: [0, 1, 2, 3, 4]\n",
      "  First row: [\"DONATE NOW √ó  donate_now.onclick = function()  { var modal_2 = document.getElementById('myModal');  var span_2 = document.getElementsByClassName('close_2')[0];  modal_2.style.display = 'block'; // show modal  // When the user clicks on <span> (x), close the modal  span_2.onclick = function()  {  modal_2.style.display = 'none'; } }\", 'Share On:', np.float64(nan), np.float64(nan), np.float64(nan)]\n",
      "\n",
      "\n",
      "Table 8:\n",
      "  Shape: (1, 9)\n",
      "  Columns: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "  First row: ['Download App', np.float64(nan), 'Follow us on', np.float64(nan), np.float64(nan)]\n",
      "\n",
      "\n",
      "üîç METHOD 2: BeautifulSoup\n",
      "----------------------------------------------------------------------\n",
      "Total <table> tags found: 8\n",
      "\n",
      "\n",
      "Table 1:\n",
      "  Total <tr> rows: 1\n",
      "  First row: ['', '']\n",
      "\n",
      "\n",
      "Table 2:\n",
      "  Total <tr> rows: 1\n",
      "  First row: ['', '']\n",
      "\n",
      "\n",
      "Table 3:\n",
      "  Total <tr> rows: 9\n",
      "  First row: ['HIGHLIGHTS OF CANDIDATES']\n",
      "  Second row: []\n",
      "\n",
      "\n",
      "Table 4:\n",
      "  Total <tr> rows: 8\n",
      "  First row: ['HIGHLIGHTS OF WINNERS']\n",
      "  Second row: ['Total winners analyzed by NEW', '543']\n",
      "\n",
      "\n",
      "Table 5:\n",
      "  Total <tr> rows: 1\n",
      "  First row: ['Sno', 'Candidate‚àá', 'Constituency', 'Party', 'Criminal Case', 'Education', 'Total Assets', 'Liabilities']\n",
      "\n",
      "\n",
      "Table 6:\n",
      "  Total <tr> rows: 3\n",
      "  First row: ['DONATE NOW√óShare On:', 'DONATE NOW√ó', 'Share On:', '', '', '', 'Download AppFollow us on', 'Download App']\n",
      "  Second row: ['DONATE NOW√ó', 'Share On:', '', '', '']\n",
      "\n",
      "\n",
      "Table 7:\n",
      "  Total <tr> rows: 1\n",
      "  First row: ['DONATE NOW√ó', 'Share On:', '', '', '']\n",
      "\n",
      "\n",
      "Table 8:\n",
      "  Total <tr> rows: 1\n",
      "  First row: ['Download App', '', 'Follow us on', '', '', '', '', '']\n",
      "\n",
      "\n",
      "üìÑ METHOD 3: Page Source Check\n",
      "----------------------------------------------------------------------\n",
      "‚úó 'Abu Bakar' NOT in HTML\n",
      "‚úì Found 'Candidate' header in HTML\n",
      "‚úì HTML contains 8 <table> tags\n",
      "‚úì HTML contains 0 <tbody> tags\n",
      "\n",
      "======================================================================\n",
      "DIAGNOSTIC COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://myneta.info/LokSabha2024/index.php?action=summary&subAction=candidates_analyzed&sort=candidate&page=1\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"COMPLETE DIAGNOSTIC\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Method 1: pandas read_html\n",
    "print(\"\\nüìä METHOD 1: pd.read_html()\")\n",
    "print(\"-\"*70)\n",
    "try:\n",
    "    dfs = pd.read_html(url)\n",
    "    print(f\"Total tables found: {len(dfs)}\\n\")\n",
    "    \n",
    "    for i, df in enumerate(dfs):\n",
    "        print(f\"\\nTable {i+1}:\")\n",
    "        print(f\"  Shape: {df.shape}\")\n",
    "        print(f\"  Columns: {df.columns.tolist()}\")\n",
    "        if len(df) > 0:\n",
    "            print(f\"  First row: {df.iloc[0].tolist()[:5]}\")  # First 5 values\n",
    "        print()\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Method 2: BeautifulSoup\n",
    "print(\"\\nüîç METHOD 2: BeautifulSoup\")\n",
    "print(\"-\"*70)\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    tables = soup.find_all('table')\n",
    "    print(f\"Total <table> tags found: {len(tables)}\\n\")\n",
    "    \n",
    "    for i, table in enumerate(tables):\n",
    "        print(f\"\\nTable {i+1}:\")\n",
    "        \n",
    "        # Count rows\n",
    "        all_rows = table.find_all('tr')\n",
    "        print(f\"  Total <tr> rows: {len(all_rows)}\")\n",
    "        \n",
    "        # Get first row\n",
    "        if len(all_rows) > 0:\n",
    "            first_row = all_rows[0]\n",
    "            cells = first_row.find_all(['th', 'td'])\n",
    "            headers = [cell.get_text(strip=True) for cell in cells]\n",
    "            print(f\"  First row: {headers[:8]}\")\n",
    "        \n",
    "        # Get second row (actual data)\n",
    "        if len(all_rows) > 1:\n",
    "            second_row = all_rows[1]\n",
    "            cells = second_row.find_all('td')\n",
    "            data = [cell.get_text(strip=True) for cell in cells]\n",
    "            print(f\"  Second row: {data[:8]}\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Method 3: Check page source\n",
    "print(\"\\nüìÑ METHOD 3: Page Source Check\")\n",
    "print(\"-\"*70)\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    html = response.text\n",
    "    \n",
    "    # Search for candidate names we know exist\n",
    "    if \"Abu Bakar\" in html:\n",
    "        print(\"‚úì Found 'Abu Bakar' in HTML\")\n",
    "    else:\n",
    "        print(\"‚úó 'Abu Bakar' NOT in HTML\")\n",
    "    \n",
    "    if \"Candidate\" in html:\n",
    "        print(\"‚úì Found 'Candidate' header in HTML\")\n",
    "    else:\n",
    "        print(\"‚úó 'Candidate' header NOT in HTML\")\n",
    "    \n",
    "    # Count table tags\n",
    "    table_count = html.count('<table')\n",
    "    print(f\"‚úì HTML contains {table_count} <table> tags\")\n",
    "    \n",
    "    # Check for tbody\n",
    "    tbody_count = html.count('<tbody')\n",
    "    print(f\"‚úì HTML contains {tbody_count} <tbody> tags\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DIAGNOSTIC COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5f2ed44-c4b2-4dce-9af2-dcfe35352450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MyNeta Scraper - Selenium Version\n",
      "============================================================\n",
      "\n",
      "Setting up browser...\n",
      "Testing page 1...\n",
      "  ‚úì Page 1: 100 records\n",
      "\n",
      "‚úÖ SUCCESS!\n",
      "\n",
      "Shape: (100, 8)\n",
      "Columns: ['Sno', 'Candidate‚àá', 'Constituency', 'Party', 'Criminal Case', 'Education', 'Total Assets', 'Liabilities']\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Candidate‚àá</th>\n",
       "      <th>Constituency</th>\n",
       "      <th>Party</th>\n",
       "      <th>Criminal Case</th>\n",
       "      <th>Education</th>\n",
       "      <th>Total Assets</th>\n",
       "      <th>Liabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Abu Bakar Rahmani</td>\n",
       "      <td>MADHUBANI</td>\n",
       "      <td>Country Citizen Party</td>\n",
       "      <td>0</td>\n",
       "      <td>Post Graduate</td>\n",
       "      <td>Rs¬†13,58,312  ~ 13¬†Lacs+</td>\n",
       "      <td>Rs¬†0  ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Adv Najib Shaikh</td>\n",
       "      <td>AKOLA</td>\n",
       "      <td>Indian National League</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate Professional</td>\n",
       "      <td>Rs¬†25,87,782  ~ 25¬†Lacs+</td>\n",
       "      <td>Rs¬†18,00,000  ~ 18¬†Lacs+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Advocate Balwinder Kumar</td>\n",
       "      <td>JALANDHAR (SC)</td>\n",
       "      <td>BSP</td>\n",
       "      <td>1</td>\n",
       "      <td>Post Graduate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Anandswamy Gaddadevarmath</td>\n",
       "      <td>HAVERI</td>\n",
       "      <td>INC</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Rs¬†56,81,54,912  ~ 56¬†Crore+</td>\n",
       "      <td>Rs¬†22,46,68,569  ~ 22¬†Crore+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bhagyaraj. J</td>\n",
       "      <td>VILUPPURAM (SC)</td>\n",
       "      <td>AIADMK</td>\n",
       "      <td>0</td>\n",
       "      <td>12th Pass</td>\n",
       "      <td>Rs¬†4,79,83,303  ~ 4¬†Crore+</td>\n",
       "      <td>Rs¬†1,43,64,469  ~ 1¬†Crore+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sno                 Candidate‚àá     Constituency                   Party  \\\n",
       "0    1          Abu Bakar Rahmani        MADHUBANI   Country Citizen Party   \n",
       "1    2           Adv Najib Shaikh            AKOLA  Indian National League   \n",
       "2    3   Advocate Balwinder Kumar   JALANDHAR (SC)                     BSP   \n",
       "3    4  Anandswamy Gaddadevarmath           HAVERI                     INC   \n",
       "4    5               Bhagyaraj. J  VILUPPURAM (SC)                  AIADMK   \n",
       "\n",
       "   Criminal Case              Education                  Total Assets  \\\n",
       "0              0          Post Graduate      Rs¬†13,58,312  ~ 13¬†Lacs+   \n",
       "1              0  Graduate Professional      Rs¬†25,87,782  ~ 25¬†Lacs+   \n",
       "2              1          Post Graduate                           NaN   \n",
       "3              1               Graduate  Rs¬†56,81,54,912  ~ 56¬†Crore+   \n",
       "4              0              12th Pass    Rs¬†4,79,83,303  ~ 4¬†Crore+   \n",
       "\n",
       "                    Liabilities  \n",
       "0                       Rs¬†0  ~  \n",
       "1      Rs¬†18,00,000  ~ 18¬†Lacs+  \n",
       "2                           NaN  \n",
       "3  Rs¬†22,46,68,569  ~ 22¬†Crore+  \n",
       "4    Rs¬†1,43,64,469  ~ 1¬†Crore+  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scrape all 84 pages? (y/n):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting full scrape...\n",
      "This will take ~10 minutes (84 pages √ó 7 seconds)\n",
      "\n",
      "[2/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 2: 100 records\n",
      "\n",
      "[3/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 3: 100 records\n",
      "\n",
      "[4/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 4: 100 records\n",
      "\n",
      "[5/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 5: 100 records\n",
      "\n",
      "[6/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 6: 100 records\n",
      "\n",
      "[7/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 7: 100 records\n",
      "\n",
      "[8/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 8: 100 records\n",
      "\n",
      "[9/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 9: 100 records\n",
      "\n",
      "[10/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 10: 100 records\n",
      "\n",
      "  üíæ Saved: 1000 records\n",
      "\n",
      "[11/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 11: 100 records\n",
      "\n",
      "[12/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 12: 100 records\n",
      "\n",
      "[13/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 13: 100 records\n",
      "\n",
      "[14/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 14: 100 records\n",
      "\n",
      "[15/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 15: 100 records\n",
      "\n",
      "[16/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 16: 100 records\n",
      "\n",
      "[17/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 17: 100 records\n",
      "\n",
      "[18/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 18: 100 records\n",
      "\n",
      "[19/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 19: 100 records\n",
      "\n",
      "[20/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 20: 100 records\n",
      "\n",
      "  üíæ Saved: 2000 records\n",
      "\n",
      "[21/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 21: 100 records\n",
      "\n",
      "[22/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 22: 100 records\n",
      "\n",
      "[23/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 23: 100 records\n",
      "\n",
      "[24/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 24: 100 records\n",
      "\n",
      "[25/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 25: 100 records\n",
      "\n",
      "[26/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 26: 100 records\n",
      "\n",
      "[27/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 27: 100 records\n",
      "\n",
      "[28/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 28: 100 records\n",
      "\n",
      "[29/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 29: 100 records\n",
      "\n",
      "[30/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 30: 100 records\n",
      "\n",
      "  üíæ Saved: 3000 records\n",
      "\n",
      "[31/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 31: 100 records\n",
      "\n",
      "[32/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 32: 100 records\n",
      "\n",
      "[33/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 33: 100 records\n",
      "\n",
      "[34/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 34: 100 records\n",
      "\n",
      "[35/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 35: 100 records\n",
      "\n",
      "[36/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 36: 100 records\n",
      "\n",
      "[37/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 37: 100 records\n",
      "\n",
      "[38/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 38: 100 records\n",
      "\n",
      "[39/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 39: 100 records\n",
      "\n",
      "[40/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 40: 100 records\n",
      "\n",
      "  üíæ Saved: 4000 records\n",
      "\n",
      "[41/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 41: 100 records\n",
      "\n",
      "[42/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 42: 100 records\n",
      "\n",
      "[43/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 43: 100 records\n",
      "\n",
      "[44/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 44: 100 records\n",
      "\n",
      "[45/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 45: 100 records\n",
      "\n",
      "[46/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 46: 100 records\n",
      "\n",
      "[47/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 47: 100 records\n",
      "\n",
      "[48/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 48: 100 records\n",
      "\n",
      "[49/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 49: 100 records\n",
      "\n",
      "[50/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 50: 100 records\n",
      "\n",
      "  üíæ Saved: 5000 records\n",
      "\n",
      "[51/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 51: 100 records\n",
      "\n",
      "[52/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 52: 100 records\n",
      "\n",
      "[53/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 53: 100 records\n",
      "\n",
      "[54/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 54: 100 records\n",
      "\n",
      "[55/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 55: 100 records\n",
      "\n",
      "[56/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 56: 100 records\n",
      "\n",
      "[57/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 57: 100 records\n",
      "\n",
      "[58/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 58: 100 records\n",
      "\n",
      "[59/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 59: 100 records\n",
      "\n",
      "[60/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 60: 100 records\n",
      "\n",
      "  üíæ Saved: 6000 records\n",
      "\n",
      "[61/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 61: 100 records\n",
      "\n",
      "[62/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 62: 100 records\n",
      "\n",
      "[63/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 63: 100 records\n",
      "\n",
      "[64/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 64: 100 records\n",
      "\n",
      "[65/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 65: 100 records\n",
      "\n",
      "[66/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 66: 100 records\n",
      "\n",
      "[67/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 67: 100 records\n",
      "\n",
      "[68/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 68: 100 records\n",
      "\n",
      "[69/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 69: 100 records\n",
      "\n",
      "[70/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 70: 100 records\n",
      "\n",
      "  üíæ Saved: 7000 records\n",
      "\n",
      "[71/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 71: 100 records\n",
      "\n",
      "[72/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 72: 100 records\n",
      "\n",
      "[73/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 73: 100 records\n",
      "\n",
      "[74/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 74: 100 records\n",
      "\n",
      "[75/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 75: 100 records\n",
      "\n",
      "[76/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 76: 100 records\n",
      "\n",
      "[77/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 77: 100 records\n",
      "\n",
      "[78/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 78: 100 records\n",
      "\n",
      "[79/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 79: 100 records\n",
      "\n",
      "[80/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 80: 100 records\n",
      "\n",
      "  üíæ Saved: 8000 records\n",
      "\n",
      "[81/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 81: 100 records\n",
      "\n",
      "[82/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 82: 100 records\n",
      "\n",
      "[83/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 83: 100 records\n",
      "\n",
      "[84/84] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\2747256413.py:45: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(html)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Page 84: 38 records\n",
      "\n",
      "\n",
      "‚úÖ COMPLETE! 8338 records saved\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MyNeta Scraper - Selenium Version\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Setup Chrome driver\"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')  # Run in background\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    \n",
    "    driver = webdriver.Chrome(\n",
    "        service=Service(ChromeDriverManager().install()),\n",
    "        options=options\n",
    "    )\n",
    "    return driver\n",
    "\n",
    "def scrape_page_selenium(driver, page_num):\n",
    "    \"\"\"Scrape a page using Selenium\"\"\"\n",
    "    try:\n",
    "        url = f\"https://myneta.info/LokSabha2024/index.php?action=summary&subAction=candidates_analyzed&sort=candidate&page={page_num}\"\n",
    "        \n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for table to load (wait for rows to appear)\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        wait.until(EC.presence_of_element_located((By.TAG_NAME, \"table\")))\n",
    "        \n",
    "        # Give it extra time for JavaScript to populate\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Get page source after JavaScript has loaded\n",
    "        html = driver.page_source\n",
    "        \n",
    "        # Now use pandas to parse\n",
    "        dfs = pd.read_html(html)\n",
    "        \n",
    "        # Table 5 should now have data\n",
    "        if len(dfs) >= 5:\n",
    "            df = dfs[4]  # 5th table (index 4)\n",
    "            \n",
    "            # Check if it has data\n",
    "            if len(df) > 0:\n",
    "                print(f\"  ‚úì Page {page_num}: {len(df)} records\")\n",
    "                return df\n",
    "            else:\n",
    "                print(f\"  ‚úó Page {page_num}: Table empty\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"  ‚úó Page {page_num}: Not enough tables\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó Page {page_num}: Error - {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Test with page 1\n",
    "print(\"\\nSetting up browser...\")\n",
    "driver = setup_driver()\n",
    "\n",
    "print(\"Testing page 1...\")\n",
    "df_test = scrape_page_selenium(driver, 1)\n",
    "\n",
    "if df_test is not None and len(df_test) > 0:\n",
    "    print(\"\\n‚úÖ SUCCESS!\\n\")\n",
    "    print(f\"Shape: {df_test.shape}\")\n",
    "    print(f\"Columns: {df_test.columns.tolist()}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    display(df_test.head())\n",
    "    \n",
    "    proceed = input(\"\\n\\nScrape all 84 pages? (y/n): \")\n",
    "    \n",
    "    if proceed.lower() == 'y':\n",
    "        print(\"\\nüöÄ Starting full scrape...\")\n",
    "        print(\"This will take ~10 minutes (84 pages √ó 7 seconds)\")\n",
    "        \n",
    "        all_data = [df_test]\n",
    "        \n",
    "        for page in range(2, 85):\n",
    "            print(f\"\\n[{page}/84] \", end=\"\")\n",
    "            df = scrape_page_selenium(driver, page)\n",
    "            \n",
    "            if df is not None and len(df) > 0:\n",
    "                all_data.append(df)\n",
    "            \n",
    "            # Save progress every 10 pages\n",
    "            if page % 10 == 0:\n",
    "                temp = pd.concat(all_data, ignore_index=True)\n",
    "                temp.to_excel('../data/raw/progress.xlsx', index=False)\n",
    "                print(f\"\\n  üíæ Saved: {len(temp)} records\")\n",
    "            \n",
    "            time.sleep(2)  # 2 seconds between pages\n",
    "        \n",
    "        # Close browser\n",
    "        driver.quit()\n",
    "        \n",
    "        # Final save\n",
    "        final_df = pd.concat(all_data, ignore_index=True)\n",
    "        final_df = final_df.drop_duplicates()\n",
    "        final_df.to_excel('../data/raw/lok_sabha_2024_full.xlsx', index=False)\n",
    "        \n",
    "        print(f\"\\n\\n‚úÖ COMPLETE! {len(final_df)} records saved\")\n",
    "        df = final_df\n",
    "        \n",
    "    else:\n",
    "        driver.quit()\n",
    "        print(\"\\nCancelled\")\n",
    "        df = df_test\n",
    "else:\n",
    "    driver.quit()\n",
    "    print(\"\\n‚ùå Failed. Need different approach.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64e9f618-d860-4421-88da-ca9f93f33ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sno</th>\n",
       "      <th>Candidate‚àá</th>\n",
       "      <th>Constituency</th>\n",
       "      <th>Party</th>\n",
       "      <th>Criminal Case</th>\n",
       "      <th>Education</th>\n",
       "      <th>Total Assets</th>\n",
       "      <th>Liabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Abu Bakar Rahmani</td>\n",
       "      <td>MADHUBANI</td>\n",
       "      <td>Country Citizen Party</td>\n",
       "      <td>0</td>\n",
       "      <td>Post Graduate</td>\n",
       "      <td>Rs¬†13,58,312  ~ 13¬†Lacs+</td>\n",
       "      <td>Rs¬†0  ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Adv Najib Shaikh</td>\n",
       "      <td>AKOLA</td>\n",
       "      <td>Indian National League</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate Professional</td>\n",
       "      <td>Rs¬†25,87,782  ~ 25¬†Lacs+</td>\n",
       "      <td>Rs¬†18,00,000  ~ 18¬†Lacs+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Advocate Balwinder Kumar</td>\n",
       "      <td>JALANDHAR (SC)</td>\n",
       "      <td>BSP</td>\n",
       "      <td>1</td>\n",
       "      <td>Post Graduate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Anandswamy Gaddadevarmath</td>\n",
       "      <td>HAVERI</td>\n",
       "      <td>INC</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Rs¬†56,81,54,912  ~ 56¬†Crore+</td>\n",
       "      <td>Rs¬†22,46,68,569  ~ 22¬†Crore+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Bhagyaraj. J</td>\n",
       "      <td>VILUPPURAM (SC)</td>\n",
       "      <td>AIADMK</td>\n",
       "      <td>0</td>\n",
       "      <td>12th Pass</td>\n",
       "      <td>Rs¬†4,79,83,303  ~ 4¬†Crore+</td>\n",
       "      <td>Rs¬†1,43,64,469  ~ 1¬†Crore+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sno                 Candidate‚àá     Constituency                   Party  \\\n",
       "0    1          Abu Bakar Rahmani        MADHUBANI   Country Citizen Party   \n",
       "1    2           Adv Najib Shaikh            AKOLA  Indian National League   \n",
       "2    3   Advocate Balwinder Kumar   JALANDHAR (SC)                     BSP   \n",
       "3    4  Anandswamy Gaddadevarmath           HAVERI                     INC   \n",
       "4    5               Bhagyaraj. J  VILUPPURAM (SC)                  AIADMK   \n",
       "\n",
       "   Criminal Case              Education                  Total Assets  \\\n",
       "0              0          Post Graduate      Rs¬†13,58,312  ~ 13¬†Lacs+   \n",
       "1              0  Graduate Professional      Rs¬†25,87,782  ~ 25¬†Lacs+   \n",
       "2              1          Post Graduate                           NaN   \n",
       "3              1               Graduate  Rs¬†56,81,54,912  ~ 56¬†Crore+   \n",
       "4              0              12th Pass    Rs¬†4,79,83,303  ~ 4¬†Crore+   \n",
       "\n",
       "                    Liabilities  \n",
       "0                       Rs¬†0  ~  \n",
       "1      Rs¬†18,00,000  ~ 18¬†Lacs+  \n",
       "2                           NaN  \n",
       "3  Rs¬†22,46,68,569  ~ 22¬†Crore+  \n",
       "4    Rs¬†1,43,64,469  ~ 1¬†Crore+  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6a98a29-426c-4233-b049-5ae3dae867c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Saved 8338 records!\n",
      "   Location: data/raw/lok_sabha_2024_full.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Save the complete dataset\n",
    "final_df.to_excel('../data/raw/lok_sabha_2024_full.xlsx', index=False)\n",
    "final_df.to_csv('../data/raw/lok_sabha_2024_full.csv', index=False)  # Backup as CSV\n",
    "\n",
    "print(f\"‚úÖ Saved {len(final_df)} records!\")\n",
    "print(f\"   Location: data/raw/lok_sabha_2024_full.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d622069-1c55-4558-b181-dbbb1b3cad2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET OVERVIEW\n",
      "============================================================\n",
      "Total Records: 8338\n",
      "Total Columns: 8\n",
      "\n",
      "Columns: ['Sno', 'Candidate‚àá', 'Constituency', 'Party', 'Criminal Case', 'Education', 'Total Assets', 'Liabilities']\n",
      "\n",
      "============================================================\n",
      "DATA QUALITY CHECK\n",
      "============================================================\n",
      "\n",
      "Missing Values:\n",
      "Sno                 0\n",
      "Candidate‚àá          0\n",
      "Constituency        0\n",
      "Party               0\n",
      "Criminal Case       0\n",
      "Education           0\n",
      "Total Assets     2779\n",
      "Liabilities      2779\n",
      "dtype: int64\n",
      "\n",
      "Duplicates: 0\n",
      "\n",
      "Data Types:\n",
      "Sno               int64\n",
      "Candidate‚àá       object\n",
      "Constituency     object\n",
      "Party            object\n",
      "Criminal Case     int64\n",
      "Education        object\n",
      "Total Assets     object\n",
      "Liabilities      object\n",
      "dtype: object\n",
      "\n",
      "============================================================\n",
      "QUICK STATISTICS\n",
      "============================================================\n",
      "\n",
      "Top 10 Parties:\n",
      "Party\n",
      "IND                                    3907\n",
      "BSP                                     488\n",
      "BJP                                     440\n",
      "INC                                     328\n",
      "SUCI(C)                                 149\n",
      "Peoples Party of India (Democratic)      79\n",
      "SP                                       71\n",
      "CPI(M)                                   52\n",
      "AITC                                     48\n",
      "Bharatheeya Jawan Kisan Party            41\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Candidates with criminal cases: 1645\n",
      "Percentage: 19.7%\n",
      "\n",
      "Education Levels:\n",
      "Education\n",
      "Post Graduate            1538\n",
      "Graduate                 1498\n",
      "12th Pass                1301\n",
      "10th Pass                1172\n",
      "Graduate Professional     979\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:37: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:37: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\radha\\AppData\\Local\\Temp\\ipykernel_14528\\1477687932.py:37: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  criminal = df['Criminal Case'].astype(str).str.extract('(\\d+)')[0].astype(float)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = final_df  # Your scraped data\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Records: {len(df)}\")\n",
    "print(f\"Total Columns: {len(df.columns)}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DATA QUALITY CHECK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Duplicates\n",
    "print(f\"\\nDuplicates: {df.duplicated().sum()}\")\n",
    "\n",
    "# Data types\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"QUICK STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Party distribution\n",
    "print(\"\\nTop 10 Parties:\")\n",
    "print(df['Party'].value_counts().head(10))\n",
    "\n",
    "# Criminal cases\n",
    "if 'Criminal Case' in df.columns:\n",
    "    criminal = df['Criminal Case'].astype(str).str.extract('(\\d+)')[0].astype(float)\n",
    "    print(f\"\\nCandidates with criminal cases: {(criminal > 0).sum()}\")\n",
    "    print(f\"Percentage: {(criminal > 0).sum() / len(df) * 100:.1f}%\")\n",
    "\n",
    "# Education\n",
    "if 'Education' in df.columns:\n",
    "    print(\"\\nEducation Levels:\")\n",
    "    print(df['Education'].value_counts().head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6330d1d-58f2-4743-a0ef-5a76527cba82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
